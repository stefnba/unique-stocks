# https://stackoverflow.com/questions/68194327/how-to-configure-celery-worker-on-distributed-airflow-architecture-using-docker
version: '3.8'

x-airflow-common: &airflow-common
    build:
        context: .
        dockerfile: docker/Dockerfile
        args:
            AIRFLOW_HOME: ${AIRFLOW_HOME}
            AIRFLOW_PROJ_DIR: ${AIRFLOW_PROJ_DIR}
    env_file:
        - .env
    environment: &airflow-common-env
        ENV: DockerDevelopment
        AIRFLOW_HOME: ${AIRFLOW_HOME}
        TEMP_DIR_PATH: ${AIRFLOW_HOME}/temp
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@airflow-postgres/${AIRFLOW_DB_NAME}
        PYTHONPATH: ${AIRFLOW_HOME}/include # add include custom code
        AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
        AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
        AIRFLOW__CORE__MAX_MAP_LENGTH: 100000
        AIRFLOW__CORE__EXECUTOR: CeleryExecutor
        AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@airflow-postgres/${AIRFLOW_DB_NAME}
        AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
        LOGGING_REMOTE_HOST: http://unique-stocks-log
    user: '${AIRFLOW_UID:-50000}:0'
    volumes:
        - ${AIRFLOW_PROJ_DIR}/dags:${AIRFLOW_HOME}/dags
        - ${AIRFLOW_PROJ_DIR}/logs:${AIRFLOW_HOME}/logs
        - ${AIRFLOW_PROJ_DIR}/plugins:${AIRFLOW_HOME}/plugins
        - ${AIRFLOW_PROJ_DIR}/include:${AIRFLOW_HOME}/include
    depends_on: &airflow-common-depends-on
        airflow-postgres:
            condition: service_healthy
    networks:
        - unique-stocks-network
        - default

services:
    airflow-webserver:
        <<: *airflow-common
        depends_on:
            - airflow-postgres
        ports:
            - '8080:8080'
        entrypoint: ${AIRFLOW_HOME}/airflow_init.sh
        restart: always

    airflow-scheduler:
        <<: *airflow-common
        command: scheduler
        depends_on:
            - airflow-webserver
    redis:
        image: redis:latest
        expose:
            - 6379
        healthcheck:
            test: ['CMD', 'redis-cli', 'ping']
            interval: 10s
            timeout: 30s
            retries: 50
            start_period: 30s
        restart: always
    airflow-worker:
        <<: *airflow-common
        command: airflow celery worker
        healthcheck:
            # yamllint disable rule:line-length
            test:
                - 'CMD-SHELL'
                - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
            interval: 30s
            timeout: 10s
            retries: 5
            start_period: 30s
        environment:
            <<: *airflow-common-env
            # Required to handle warm shutdown of the celery workers properly
            # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
            DUMB_INIT_SETSID: '0'
        restart: always
        depends_on:
            <<: *airflow-common-depends-on
    airflow-worker-2:
        <<: *airflow-common
        command: airflow celery worker
        healthcheck:
            # yamllint disable rule:line-length
            test:
                - 'CMD-SHELL'
                - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
            interval: 30s
            timeout: 10s
            retries: 5
            start_period: 30s
        environment:
            <<: *airflow-common-env
            # Required to handle warm shutdown of the celery workers properly
            # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
            DUMB_INIT_SETSID: '0'
        restart: always
        depends_on:
            <<: *airflow-common-depends-on
    airflow-worker-3:
        <<: *airflow-common
        command: airflow celery worker
        healthcheck:
            # yamllint disable rule:line-length
            test:
                - 'CMD-SHELL'
                - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
            interval: 30s
            timeout: 10s
            retries: 5
            start_period: 30s
        environment:
            <<: *airflow-common-env
            # Required to handle warm shutdown of the celery workers properly
            # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
            DUMB_INIT_SETSID: '0'
        restart: always
        depends_on:
            <<: *airflow-common-depends-on
    flower:
        <<: *airflow-common
        command: celery flower --basic-auth=admin:password
        # profiles:
        #     - flower
        ports:
            - '5555:5555'
        healthcheck:
            test: ['CMD', 'curl', '--fail', 'http://localhost:5555/']
            interval: 30s
            timeout: 10s
            retries: 5
            start_period: 30s
        restart: always
        depends_on:
            <<: *airflow-common-depends-on
    # airflow-triggerer:
    #     <<: *airflow-common
    #     command: triggerer
    #     healthcheck:
    #         test:
    #             [
    #                 'CMD-SHELL',
    #                 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"'
    #             ]
    #         interval: 30s
    #         timeout: 10s
    #         retries: 5
    #         start_period: 30s
    #     restart: always
    #     depends_on:
    #         <<: *airflow-common-depends-on
