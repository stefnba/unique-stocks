version: '3.8'

x-airflow-common: &airflow-common
    build:
        context: .
        dockerfile: docker/Dockerfile
        args:
            AIRFLOW_HOME: ${AIRFLOW_HOME:-/app/airflow}
            AIRFLOW_PROJ_DIR: ${AIRFLOW_PROJ_DIR:-./pipelines}
    env_file:
        - .env
    environment: &airflow-common-env
        AIRFLOW_HOME: ${AIRFLOW_HOME:-/app/airflow}
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@airflow-postgres/${AIRFLOW_DB_NAME}
        PYTHONPATH: /app/airflow # allow packages from outside dags folder
        AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    user: '${AIRFLOW_UID:-50000}:0'
    volumes:
        - ${AIRFLOW_PROJ_DIR:-./pipelines}/dags:${AIRFLOW_HOME:-/app/airflow}/dags
        - ${AIRFLOW_PROJ_DIR:-./pipelines}/logs:${AIRFLOW_HOME:-/app/airflow}/logs
        - ${AIRFLOW_PROJ_DIR:-./pipelines}/plugins:${AIRFLOW_HOME:-/app/airflow}/plugins
        - ${AIRFLOW_PROJ_DIR:-./pipelines}/services:${AIRFLOW_HOME:-/app/airflow}/services
    depends_on: &airflow-common-depends-on
        airflow-redis:
            condition: service_healthy
        airflow-postgres:
            condition: service_healthy

services:
    airflow-webserver:
        environment:
            <<: *airflow-common-env
    airflow-scheduler:
        environment:
            <<: *airflow-common-env
    airflow-redis:
        image: redis:latest
        expose:
            - 6379
        healthcheck:
            test: ['CMD', 'redis-cli', 'ping']
            interval: 5s
            timeout: 30s
            retries: 50
        restart: always
    airflow-worker:
        <<: *airflow-common
        command: celery worker
        healthcheck:
            test:
                - 'CMD-SHELL'
                - 'celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
            interval: 10s
            timeout: 10s
            retries: 5
        environment:
            <<: *airflow-common-env
            # Required to handle warm shutdown of the celery workers properly
            # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
            DUMB_INIT_SETSID: '0'
        restart: always
        depends_on:
            <<: *airflow-common-depends-on

volumes:
    airflow-postgres-data:
